# -*- coding: utf-8 -*-
"""CIS192 Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YCeCHetQvaGm93Ry6hs1vXRLHjjW-RyV
"""

#!pip install pyyaml h5py  
!pip install pillow
import sys
from PIL import Image

from __future__ import print_function
import tensorflow as tf
import keras
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization,GlobalAveragePooling2D
from tensorflow.keras.optimizers import SGD,RMSprop,Adam,Adadelta,Adagrad,Adamax,Nadam,Ftrl
from tensorflow.keras.utils import to_categorical
from keras import regularizers
import numpy as np
from keras.preprocessing import image

!unzip test.zip -d test
!unzip train.zip -d train

##some preprocessing
# DEFINING *SOME* HYPERPARAMETERS
IMG_HEIGHT = 48
IMG_WIDTH = 48
BATCH_SIZE = 64
EPOCHS = 30
SEED = 12
CLASS_LABELS  = ['angry', 'fearful', 'happy', 'neutral', 'sad', "surprised"]
FINE_TUNING_EPOCHS = 20
LR = 0.01
NUM_CLASSES = 6
EARLY_STOPPING_CRITERIA=3

CLASS_LABELS_EMOJIS = ["üëø", "ü§¢" , "üò±" , "üòä" , "üòê ", "üòî" , "üò≤" ]
train_dir = "./train/train"
test_dir = "./test/test"
train_pre = ImageDataGenerator(horizontal_flip=True,
                                   width_shift_range=0.1,
                                   height_shift_range=0.1,
                                   rescale = 1./255,
                                   validation_split = 0.2,
                                  )
test_pre = ImageDataGenerator(rescale = 1./255,
                                  validation_split = 0.2,
                               )

train_generator = train_pre.flow_from_directory(directory = train_dir,
                                                    target_size = (IMG_HEIGHT ,IMG_WIDTH),
                                                    batch_size = BATCH_SIZE,
                                                    shuffle  = True , 
                                                    color_mode = "grayscale",
                                                    class_mode = "categorical",
                                                    subset = "training",
                                                    seed = 12
                                                   )
validation_generator = test_pre.flow_from_directory(directory = test_dir,
                                                         target_size = (IMG_HEIGHT ,IMG_WIDTH),
                                                         batch_size = BATCH_SIZE,
                                                         shuffle  = True , 
                                                         color_mode = "grayscale",
                                                         class_mode = "categorical",
                                                         subset = "validation",
                                                         seed = 12
                                                        )
#Found 21343 images belonging to 6 classes.
#Found 1410 images belonging to 6 classes.

input_shape = (48, 48, 1)

# MODEL DEFINITION (some hardcodede hyperparameters)
model = Sequential()

model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48, 48,1)))
model.add(Conv2D(64,(3,3), padding='same', activation='relu' ))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(128,(5,5), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
    
model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten()) 
model.add(Dense(256,activation = 'relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))
    
model.add(Dense(512,activation = 'relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(Dense(6, activation='softmax'))



# MODEL COMPILATION AND TRAINING
model.compile(loss='categorical_crossentropy',
              optimizer=Adam(lr=0.0001),
              metrics=['accuracy'])

model.fit(x = train_generator,
                    epochs = 60 ,
                    validation_data = validation_generator
                    )

# MODEL EVALUATION

label_dict = {0:'Angry',1:'Fear',2:'Happy',3:'Neutral',4:'Sad',5:'Surprise'}
test_loss, test_acc   = model.evaluate(validation_generator)
model.save('model.h5')
print('Test loss:', test_loss)
print('Test accuracy:', test_acc)

'''

Epoch 1/60
334/334 [==============================] - 17s 46ms/step - loss: 9.1980 - accuracy: 0.2027 - val_loss: 8.6495 - val_accuracy: 0.2397
Epoch 2/60
334/334 [==============================] - 15s 44ms/step - loss: 8.2792 - accuracy: 0.2185 - val_loss: 7.6625 - val_accuracy: 0.2532
Epoch 3/60
334/334 [==============================] - 15s 44ms/step - loss: 7.3693 - accuracy: 0.2393 - val_loss: 6.6841 - val_accuracy: 0.3333
Epoch 4/60
334/334 [==============================] - 15s 45ms/step - loss: 6.4741 - accuracy: 0.2570 - val_loss: 5.8018 - val_accuracy: 0.3376
Epoch 5/60
334/334 [==============================] - 15s 44ms/step - loss: 5.6309 - accuracy: 0.2807 - val_loss: 5.0210 - val_accuracy: 0.3617
Epoch 6/60
334/334 [==============================] - 15s 44ms/step - loss: 4.8722 - accuracy: 0.3129 - val_loss: 4.3911 - val_accuracy: 0.3787
Epoch 7/60
334/334 [==============================] - 15s 44ms/step - loss: 4.2463 - accuracy: 0.3331 - val_loss: 3.7465 - val_accuracy: 0.4397
Epoch 8/60
334/334 [==============================] - 15s 45ms/step - loss: 3.7073 - accuracy: 0.3674 - val_loss: 3.3406 - val_accuracy: 0.4411
Epoch 9/60
334/334 [==============================] - 15s 44ms/step - loss: 3.2621 - accuracy: 0.3849 - val_loss: 2.8917 - val_accuracy: 0.4631
Epoch 10/60
334/334 [==============================] - 15s 44ms/step - loss: 2.9046 - accuracy: 0.4041 - val_loss: 2.6733 - val_accuracy: 0.4695
Epoch 11/60
334/334 [==============================] - 15s 44ms/step - loss: 2.6122 - accuracy: 0.4315 - val_loss: 2.4017 - val_accuracy: 0.4716
Epoch 12/60
334/334 [==============================] - 15s 44ms/step - loss: 2.3969 - accuracy: 0.4500 - val_loss: 2.3914 - val_accuracy: 0.4099
Epoch 13/60
334/334 [==============================] - 15s 45ms/step - loss: 2.2111 - accuracy: 0.4689 - val_loss: 2.0295 - val_accuracy: 0.5362
Epoch 14/60
334/334 [==============================] - 15s 44ms/step - loss: 2.0647 - accuracy: 0.4863 - val_loss: 1.8938 - val_accuracy: 0.5277
Epoch 15/60
334/334 [==============================] - 15s 44ms/step - loss: 1.9558 - accuracy: 0.4936 - val_loss: 1.7658 - val_accuracy: 0.5596
Epoch 16/60
334/334 [==============================] - 15s 45ms/step - loss: 1.8605 - accuracy: 0.5065 - val_loss: 1.7057 - val_accuracy: 0.5617
Epoch 17/60
334/334 [==============================] - 15s 44ms/step - loss: 1.7718 - accuracy: 0.5252 - val_loss: 1.6502 - val_accuracy: 0.5716
Epoch 18/60
334/334 [==============================] - 15s 44ms/step - loss: 1.7084 - accuracy: 0.5345 - val_loss: 1.6222 - val_accuracy: 0.5624
Epoch 19/60
334/334 [==============================] - 15s 45ms/step - loss: 1.6523 - accuracy: 0.5449 - val_loss: 1.6322 - val_accuracy: 0.5766
Epoch 20/60
334/334 [==============================] - 15s 45ms/step - loss: 1.6155 - accuracy: 0.5478 - val_loss: 1.5303 - val_accuracy: 0.5915
Epoch 21/60
334/334 [==============================] - 15s 44ms/step - loss: 1.5759 - accuracy: 0.5592 - val_loss: 1.4884 - val_accuracy: 0.5936
Epoch 22/60
334/334 [==============================] - 15s 44ms/step - loss: 1.5512 - accuracy: 0.5567 - val_loss: 1.5860 - val_accuracy: 0.5553
Epoch 23/60
334/334 [==============================] - 15s 45ms/step - loss: 1.5171 - accuracy: 0.5658 - val_loss: 1.4159 - val_accuracy: 0.6135
Epoch 24/60
334/334 [==============================] - 15s 44ms/step - loss: 1.4932 - accuracy: 0.5757 - val_loss: 1.4551 - val_accuracy: 0.5943
Epoch 25/60
334/334 [==============================] - 15s 45ms/step - loss: 1.4757 - accuracy: 0.5758 - val_loss: 1.4080 - val_accuracy: 0.6177
Epoch 26/60
334/334 [==============================] - 15s 44ms/step - loss: 1.4561 - accuracy: 0.5815 - val_loss: 1.5004 - val_accuracy: 0.5716
Epoch 27/60
334/334 [==============================] - 15s 44ms/step - loss: 1.4475 - accuracy: 0.5845 - val_loss: 1.4484 - val_accuracy: 0.6071
Epoch 28/60
334/334 [==============================] - 15s 44ms/step - loss: 1.4348 - accuracy: 0.5904 - val_loss: 1.4013 - val_accuracy: 0.6206
Epoch 29/60
334/334 [==============================] - 15s 45ms/step - loss: 1.4279 - accuracy: 0.5892 - val_loss: 1.3846 - val_accuracy: 0.6163
Epoch 30/60
334/334 [==============================] - 15s 44ms/step - loss: 1.4073 - accuracy: 0.6017 - val_loss: 1.4220 - val_accuracy: 0.6128
Epoch 31/60
334/334 [==============================] - 15s 45ms/step - loss: 1.4043 - accuracy: 0.6015 - val_loss: 1.3981 - val_accuracy: 0.6234
Epoch 32/60
334/334 [==============================] - 15s 44ms/step - loss: 1.3859 - accuracy: 0.6085 - val_loss: 1.3659 - val_accuracy: 0.6262
Epoch 33/60
334/334 [==============================] - 15s 44ms/step - loss: 1.3923 - accuracy: 0.6093 - val_loss: 1.3883 - val_accuracy: 0.6312
Epoch 34/60
334/334 [==============================] - 15s 44ms/step - loss: 1.3915 - accuracy: 0.6100 - val_loss: 1.4487 - val_accuracy: 0.6064
Epoch 35/60
334/334 [==============================] - 15s 44ms/step - loss: 1.3950 - accuracy: 0.6130 - val_loss: 1.4401 - val_accuracy: 0.6234
Epoch 36/60
334/334 [==============================] - 15s 45ms/step - loss: 1.3841 - accuracy: 0.6150 - val_loss: 1.3818 - val_accuracy: 0.6284
Epoch 37/60
334/334 [==============================] - 15s 44ms/step - loss: 1.3734 - accuracy: 0.6164 - val_loss: 1.3482 - val_accuracy: 0.6348
Epoch 38/60
334/334 [==============================] - 15s 44ms/step - loss: 1.3725 - accuracy: 0.6184 - val_loss: 1.3691 - val_accuracy: 0.6404
Epoch 39/60
334/334 [==============================] - 15s 44ms/step - loss: 1.3705 - accuracy: 0.6218 - val_loss: 1.3860 - val_accuracy: 0.6312
Epoch 40/60
334/334 [==============================] - 15s 44ms/step - loss: 1.3681 - accuracy: 0.6240 - val_loss: 1.3834 - val_accuracy: 0.6284
Epoch 41/60
334/334 [==============================] - 15s 46ms/step - loss: 1.3530 - accuracy: 0.6319 - val_loss: 1.3837 - val_accuracy: 0.6326
Epoch 42/60
334/334 [==============================] - 15s 45ms/step - loss: 1.3532 - accuracy: 0.6280 - val_loss: 1.4103 - val_accuracy: 0.6227
Epoch 43/60
334/334 [==============================] - 15s 45ms/step - loss: 1.3467 - accuracy: 0.6298 - val_loss: 1.3342 - val_accuracy: 0.6468
Epoch 44/60
334/334 [==============================] - 15s 44ms/step - loss: 1.3450 - accuracy: 0.6351 - val_loss: 1.3621 - val_accuracy: 0.6312
Epoch 45/60
334/334 [==============================] - 15s 46ms/step - loss: 1.3415 - accuracy: 0.6371 - val_loss: 1.3613 - val_accuracy: 0.6383
Epoch 46/60
334/334 [==============================] - 15s 45ms/step - loss: 1.3390 - accuracy: 0.6391 - val_loss: 1.4118 - val_accuracy: 0.6312
Epoch 47/60
334/334 [==============================] - 15s 45ms/step - loss: 1.3384 - accuracy: 0.6397 - val_loss: 1.3598 - val_accuracy: 0.6454
Epoch 48/60
334/334 [==============================] - 15s 45ms/step - loss: 1.3467 - accuracy: 0.6374 - val_loss: 1.3334 - val_accuracy: 0.6574
Epoch 49/60
334/334 [==============================] - 15s 44ms/step - loss: 1.3327 - accuracy: 0.6451 - val_loss: 1.4055 - val_accuracy: 0.6234
Epoch 50/60
334/334 [==============================] - 15s 46ms/step - loss: 1.3330 - accuracy: 0.6477 - val_loss: 1.3751 - val_accuracy: 0.6447
Epoch 51/60
334/334 [==============================] - 15s 46ms/step - loss: 1.3353 - accuracy: 0.6432 - val_loss: 1.3643 - val_accuracy: 0.6440
Epoch 52/60
334/334 [==============================] - 15s 45ms/step - loss: 1.3274 - accuracy: 0.6445 - val_loss: 1.3825 - val_accuracy: 0.6362
Epoch 53/60
334/334 [==============================] - 15s 45ms/step - loss: 1.3223 - accuracy: 0.6522 - val_loss: 1.3751 - val_accuracy: 0.6326
Epoch 54/60
334/334 [==============================] - 15s 44ms/step - loss: 1.3273 - accuracy: 0.6508 - val_loss: 1.3319 - val_accuracy: 0.6617
Epoch 55/60
334/334 [==============================] - 15s 44ms/step - loss: 1.3210 - accuracy: 0.6556 - val_loss: 1.3591 - val_accuracy: 0.6496
Epoch 56/60
334/334 [==============================] - 15s 45ms/step - loss: 1.3190 - accuracy: 0.6545 - val_loss: 1.3530 - val_accuracy: 0.6475
Epoch 57/60
334/334 [==============================] - 15s 45ms/step - loss: 1.3151 - accuracy: 0.6569 - val_loss: 1.3688 - val_accuracy: 0.6496
Epoch 58/60
334/334 [==============================] - 15s 44ms/step - loss: 1.3184 - accuracy: 0.6580 - val_loss: 1.3673 - val_accuracy: 0.6532
Epoch 59/60
334/334 [==============================] - 15s 45ms/step - loss: 1.3120 - accuracy: 0.6646 - val_loss: 1.3690 - val_accuracy: 0.6589
Epoch 60/60
334/334 [==============================] - 15s 44ms/step - loss: 1.3162 - accuracy: 0.6623 - val_loss: 1.3708 - val_accuracy: 0.6518
23/23 [==============================] - 0s 18ms/step - loss: 1.3708 - accuracy: 0.6518
Test loss: 1.3708430528640747
Test accuracy: 0.6517730355262756
'''

#the following code helps test out results 
model = tf.keras.models.load_model('model.h5')
img = image.load_img("./test/test/happy/im104.png",target_size = (48,48),color_mode = "grayscale")
img = np.array(img)
img = np.expand_dims(img,axis = 0) #makes image shape (1,48,48)
img = img.reshape(1,48,48,1)
result = model.predict(img)
result = list(result[0])
##print(result)